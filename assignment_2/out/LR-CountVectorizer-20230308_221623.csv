model,timestamp,vectorizer,train_accuracy,train_precision,train_recall,train_f1,test_accuracy,test_precision,test_recall,test_f1,model_params,vectorizer_params,train_metrics_report,test_metrics_report
LR,2023-03-08 22:16:23.308015,CountVectorizer,0.9709944751381215,0.9710257841964545,0.9709944751381215,0.9709934553110605,0.8973954222573007,0.8974068018718332,0.8973954222573007,0.8973988753205692,"{'model': 'LogisticRegression', 'model_params': {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}}","{'vectorizer': 'CountVectorizer', 'vectorizer_params': {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.int64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 0.98, 'max_features': 1000, 'min_df': 0.02, 'ngram_range': (1, 2), 'preprocessor': None, 'stop_words': None, 'strip_accents': None, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'tokenizer': None, 'vocabulary': None}}","              precision    recall  f1-score   support

        FAKE       0.97      0.98      0.97      2545
        REAL       0.97      0.97      0.97      2523

    accuracy                           0.97      5068
   macro avg       0.97      0.97      0.97      5068
weighted avg       0.97      0.97      0.97      5068
","              precision    recall  f1-score   support

        FAKE       0.89      0.90      0.90       619
        REAL       0.90      0.90      0.90       648

    accuracy                           0.90      1267
   macro avg       0.90      0.90      0.90      1267
weighted avg       0.90      0.90      0.90      1267
"
